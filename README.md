## Self-evolving Agent: A framework for autonomous evolving AR interaction based on context confidence

### [Paper](https://arxiv.org) | [Project Page](https://hoar012.github.io/RAP-Project/) | [Model](https://huggingface.co/Hoar012/RAP-LLaVA-13b) | [Data](https://github.com/Hoar012/Rap-MLLM/blob/main/data/Data.md)

| ![Self-evolving Agent](./images/1.png) |
|:--:|
| The difference between the time it takes for a self-evolving agent to reply  |

Visit our [Project Page](https://github.io/RAP-Project/) for more demostrations.

## ğŸ“‹ Contents

è‡ªè¿›åŒ–â€æ™ºèƒ½ä½“ï¼šYOLO æ„ŸçŸ¥ â†’ å‘é‡è®°å¿† â†’ çŸ¥è¯†å›¾è°± â†’ LoRA å¢é‡å­¦ä¹ 

1. ä¸€é”®å®‰è£…ï¼ˆLinux / macOSï¼‰
git clone https://github.com/yourname/Self-evolving-Agent.git
cd Self-evolving-Agent

# è‡ªåŠ¨åˆ›å»º venvã€å®‰è£…ä¾èµ–ã€ä¸‹è½½æƒé‡ã€å¯åŠ¨ Neo4j
bash scripts/run.sh


2. DEMO
```
from yolo_concept import ConceptLearner

agent = ConceptLearner(
    yolo_weights="yolo_concept_sdk/yolo_concept/data/weights/yolov8n.pt",
    neo4j_uri="bolt://localhost:7687",
    neo4j_auth=("neo4j", "password")
)
```

# å•å¼ å›¾åƒå¢é‡å­¦ä¹ 
agent.learn_from_image("desk.jpg", concepts=["keyboard", "mouse"])

# æŸ¥è¯¢å·²å­¦æ¦‚å¿µ
```
print(agent.query_concept("keyboard"))
# â†’ {'definition': 'electronic device ...', 'images': [...], 'relations': [{'type': 'PartOf', 'target': 'desk'}]}
```

# ç”¨è‡ªç„¶è¯­è¨€ç”Ÿæˆ LoRA æç¤º
```
prompt = agent.generate_prompt("A cat sitting on a keyboard under RGB lighting")
print(prompt)
```



## BibTeX

```
@InProceedings{

}
```
